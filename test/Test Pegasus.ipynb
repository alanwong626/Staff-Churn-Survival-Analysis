{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c19096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f5199dbc9a4fd285ceba0b57acd97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528d5fbe75404e9bb42a57bde9db37e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a91be5e66f6410585075a43a105ff57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "device = torch.device(\"cpu\")\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-cnn_dailymail\", device=device)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-cnn_dailymail\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f625a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Design, produce and improve data and AI products that are impactful to KaiOS monetization strategy.<n>Build and apply ML algorithm(data mining, time series forecast, model stimulation) analyze large amount of data.<n>Drive smarter A/B testing and carry out hypothesis testing through statistical inference.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Accountable for using data science methods to translate daily business observations and managing the internal application in an effective way.\n",
    "Collaborate with system architect, explore available models and propose innovative model pipelines.\n",
    "Contribute to company data-driven culture by supporting business strategies with data and communicating results to business units .   Conduct research on state-of-the-art technologies to solve business problems.\n",
    "Coordinate with the Business Development team to identify opportunities for leveraging data to drive innovative solutions for the growth of business. Monitor and analyze model performance and data accuracy. Work closely with different functional teams to implement models and monitor outcomes. Mine and analyze data from project database to drive added value for technical solutions and system development. Build up custom data models and algorithms to apply data sets. Help with presentation of project work to clients. Lead Innovation and Growth team.\n",
    "Deep dive on data consumption pattern to discover new insights regarding user behaviour .   Design, produce and improve data and AI products that are impactful to KaiOS monetization strategy.\n",
    "Develop and implement Machine Learning / A.I. / Cognitive Solution with Azure Technologies. Create or update documentation in support of development, which may include detailed specifications and data flow diagrams. End to end involvement with the team from requirement study, documentation, development, implementation, UAT and go-live support.\n",
    "End to end involvement with the team from requirement study, documentation, development, implementation, UAT and go-live support.\n",
    "Explore and master new technologies to advance customer experience solution, such as recommenders, and risk mitigation solution, such as fraud detection.\n",
    "Generate actionable analytics and insights and extend it as an integral component of major business change and investment programmes, especially focused to Customer life cycle management, campaign optimization and personalization, and other CRM related activities. Collaborate with stakeholders to deliver data science solutions to facilitate business transformation.. Taking the lead in individual use cases to ensure business needs are met and value delivered.. Bring a combination of mathematical rigor and innovative algorithm design to extract relevant insights from data.\n",
    "Identify supply-side and demand-side actors and build predictive and prescriptive models to turn data into actionable business insights. Unlock operational efficiency through big data optimization and robust statistical analyses. Drive smarter A/B testing and carry out hypothesis testing through statistical inference. Explore and master new technologies to advance . customer experience solution, such as recommenders, and risk mitigation solution, such as fraud detection. Collaborate with other teams to promote a data-driven approach within the organization, and identify data opportunities with business stakeholders.\n",
    "Maintain the data infrastructure and manage the data pipeline used for report analysis modelling .   Build and apply ML algorithm(data mining, time series forecast, model stimulation) analyze large amount of data .   Heavily involved in the research and development of new use-cases, either as part of our product road-map or based on specific business requirements.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "tokens = tokenizer(text, truncation = True, padding = \"longest\", return_tensors=\"pt\")\n",
    "summary = model.generate(**tokens)\n",
    "tokenizer.decode(summary[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "242ea267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from pytextrank import pytextrank as pt\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# nlp.add_pipe(\"textrank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "385eb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1070     1  data science solutions\n",
      "[data science solutions]\n",
      "0.1047     1  business strategies\n",
      "[business strategies]\n",
      "0.1008     1  business units\n",
      "[business units]\n",
      "0.0996     1  actionable business insights\n",
      "[actionable business insights]\n",
      "0.0981     1  business transformation\n",
      "[business transformation]\n",
      "0.0972     1  business\n",
      "[business]\n",
      "0.0971     1  business problems\n",
      "[business problems]\n",
      "0.0971     1  business stakeholders\n",
      "[business stakeholders]\n",
      "0.0968     1  business needs\n",
      "[business needs]\n",
      "0.0964     1  specific business requirements\n",
      "[specific business requirements]\n",
      "0.0958     1  custom data models\n",
      "[custom data models]\n",
      "0.0948     1  major business change\n",
      "[major business change]\n",
      "0.0943     1  daily business observations\n",
      "[daily business observations]\n",
      "0.0909     1  data science methods\n",
      "[data science methods]\n",
      "0.0906     5  data\n",
      "[data, data, data, data, data]\n",
      "0.0895     1  big data optimization\n",
      "[big data optimization]\n",
      "0.0853     1  data consumption pattern\n",
      "[data consumption pattern]\n",
      "0.0800     2  risk mitigation solution\n",
      "[risk mitigation solution, risk mitigation solution]\n",
      "0.0793     1  innovative solutions\n",
      "[innovative solutions]\n",
      "0.0793     2  customer experience solution\n",
      "[customer experience solution, customer experience solution]\n",
      "0.0759     1  data flow diagrams\n",
      "[data flow diagrams]\n",
      "0.0747     1  technical solutions\n",
      "[technical solutions]\n",
      "0.0734     1  report analysis modelling\n",
      "[report analysis modelling]\n",
      "0.0726     1  innovative model pipelines\n",
      "[innovative model pipelines]\n",
      "0.0686     1  data opportunities\n",
      "[data opportunities]\n",
      "0.0662     1  data sets\n",
      "[data sets]\n",
      "0.0661     1  system development\n",
      "[system development]\n",
      "0.0654     1  robust statistical analyses\n",
      "[robust statistical analyses]\n",
      "0.0634     1  available models\n",
      "[available models]\n",
      "0.0630     1  new insights\n",
      "[new insights]\n",
      "0.0623     2  fraud detection\n",
      "[fraud detection, fraud detection]\n",
      "0.0618     1  KaiOS monetization strategy\n",
      "[KaiOS monetization strategy]\n",
      "0.0615     1  Customer life cycle management\n",
      "[Customer life cycle management]\n",
      "0.0606     1  other CRM related activities\n",
      "[other CRM related activities]\n",
      "0.0606     1  models\n",
      "[models]\n",
      "0.0597     4  development\n",
      "[development, development, development, development]\n",
      "0.0566     3  support\n",
      "[support, support, support]\n",
      "0.0565     1  relevant insights\n",
      "[relevant insights]\n",
      "0.0564     1  statistical inference\n",
      "[statistical inference]\n",
      "0.0555     1  data and communicating results\n",
      "[data and communicating results]\n",
      "0.0551     1  other teams\n",
      "[other teams]\n",
      "0.0550     1  detailed specifications\n",
      "[detailed specifications]\n",
      "0.0545     1  innovative algorithm design\n",
      "[innovative algorithm design]\n",
      "0.0538     1  campaign optimization\n",
      "[campaign optimization]\n",
      "0.0534     1  user behaviour\n",
      "[user behaviour]\n",
      "0.0529     1  insights\n",
      "[insights]\n",
      "0.0524     2  requirement study\n",
      "[requirement study, requirement study]\n",
      "0.0520     1  data and AI products\n",
      "[data and AI products]\n",
      "0.0514     1  investment programmes\n",
      "[investment programmes]\n",
      "0.0508     1  added value\n",
      "[added value]\n",
      "0.0505     2  new technologies\n",
      "[new technologies, new technologies]\n",
      "0.0496     1  Azure Technologies\n",
      "[Azure Technologies]\n",
      "0.0484     1  Monitor and analyze model performance and data accuracy\n",
      "[Monitor and analyze model performance and data accuracy]\n",
      "0.0470     1  hypothesis testing\n",
      "[hypothesis testing]\n",
      "0.0466     1  different functional teams\n",
      "[different functional teams]\n",
      "0.0461     1  value\n",
      "[value]\n",
      "0.0447     1  individual use cases\n",
      "[individual use cases]\n",
      "0.0443     1  company data-driven culture\n",
      "[company data-driven culture]\n",
      "0.0420     1  system architect\n",
      "[system architect]\n",
      "0.0408     1  large amount\n",
      "[large amount]\n",
      "0.0396     3  documentation\n",
      "[documentation, documentation, documentation]\n",
      "0.0392     2  recommenders\n",
      "[recommenders, recommenders]\n",
      "0.0384     4  UAT\n",
      "[UAT, UAT, UAT, UAT]\n",
      "0.0382     1  project database\n",
      "[project database]\n",
      "0.0376     2  implementation\n",
      "[implementation, implementation]\n",
      "0.0374     1  the data pipeline\n",
      "[the data pipeline]\n",
      "0.0371     1  ML algorithm(data mining, time series forecast, model stimulation\n",
      "[ML algorithm(data mining, time series forecast, model stimulation]\n",
      "0.0367     1  actionable analytics\n",
      "[actionable analytics]\n",
      "0.0365     1  predictive and prescriptive models\n",
      "[predictive and prescriptive models]\n",
      "0.0362     1  project work\n",
      "[project work]\n",
      "0.0357     1  personalization\n",
      "[personalization]\n",
      "0.0356     1  algorithms\n",
      "[algorithms]\n",
      "0.0343     1  opportunities\n",
      "[opportunities]\n",
      "0.0342     1  the data infrastructure\n",
      "[the data infrastructure]\n",
      "0.0340     1  stakeholders\n",
      "[stakeholders]\n",
      "0.0331     1  daily\n",
      "[daily]\n",
      "0.0331     1  CRM\n",
      "[CRM]\n",
      "0.0322     1  clients\n",
      "[clients]\n",
      "0.0322     1  a data-driven approach\n",
      "[a data-driven approach]\n",
      "0.0318     1  new use-cases\n",
      "[new use-cases]\n",
      "0.0315     1  KaiOS\n",
      "[KaiOS]\n",
      "0.0314     1  an effective way\n",
      "[an effective way]\n",
      "0.0304     1  mathematical rigor\n",
      "[mathematical rigor]\n",
      "0.0290     1  Lead Innovation and Growth team\n",
      "[Lead Innovation and Growth team]\n",
      "0.0286     1  Design\n",
      "[Design]\n",
      "0.0285     1  smarter A/B testing\n",
      "[smarter A/B testing]\n",
      "0.0275     1  the Business Development team\n",
      "[the Business Development team]\n",
      "0.0275     1  AI\n",
      "[AI]\n",
      "0.0268     1  operational efficiency\n",
      "[operational efficiency]\n",
      "0.0268     1  part\n",
      "[part]\n",
      "0.0263     1  outcomes\n",
      "[outcomes]\n",
      "0.0258     1  the internal application\n",
      "[the internal application]\n",
      "0.0237     1  Deep dive\n",
      "[Deep dive]\n",
      "0.0234     1  an integral component\n",
      "[an integral component]\n",
      "0.0225     1  ML\n",
      "[ML]\n",
      "0.0224     1  Machine Learning / A.I. / Cognitive Solution\n",
      "[Machine Learning / A.I. / Cognitive Solution]\n",
      "0.0213     2  involvement\n",
      "[involvement, involvement]\n",
      "0.0211     1  our product road-map\n",
      "[our product road-map]\n",
      "0.0211     2  the team\n",
      "[the team, the team]\n",
      "0.0192     1  supply-side and demand-side actors\n",
      "[supply-side and demand-side actors]\n",
      "0.0188     1  presentation\n",
      "[presentation]\n",
      "0.0185     1  Machine Learning / A.I. / Cognitive Solution with\n",
      "[Machine Learning / A.I. / Cognitive Solution with]\n",
      "0.0172     1  Lead Innovation and Growth\n",
      "[Lead Innovation and Growth]\n",
      "0.0166     1  Coordinate\n",
      "[Coordinate]\n",
      "0.0166     1  Deep\n",
      "[Deep]\n",
      "0.0166     2  End\n",
      "[End, End]\n",
      "0.0166     1  Mine\n",
      "[Mine]\n",
      "0.0142     1  the Business Development\n",
      "[the Business Development]\n",
      "0.0134     1  the growth\n",
      "[the growth]\n",
      "0.0133     1    Conduct research\n",
      "[  Conduct research]\n",
      "0.0133     1  the organization\n",
      "[the organization]\n",
      "0.0096     1  the research\n",
      "[the research]\n",
      "0.0087     1  a combination\n",
      "[a combination]\n",
      "0.0087     1  the lead\n",
      "[the lead]\n",
      "0.0077     1  the-art\n",
      "[the-art]\n",
      "0.0077     1  \n",
      "Collaborate\n",
      "[\n",
      "Collaborate]\n",
      "0.0077     1  \n",
      "Explore\n",
      "[\n",
      "Explore]\n",
      "0.0000     1  it\n",
      "[it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example text\n",
    "# text = \"Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types systems and systems of mixed types.\"\n",
    "\n",
    "# load a spaCy model, depending on language, scale, etc.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe('textrank')\n",
    "# add PyTextRank to the spaCy pipeline\n",
    "# tr = pt.TextRank()\n",
    "# nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# examine the top-ranked phrases in the document\n",
    "for p in doc._.phrases:\n",
    "    print(\"{:.4f} {:5d}  {}\".format(p.rank, p.count, p.text))\n",
    "    print(p.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3858895a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pytextrank' has no attribute 'TextRank'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-59ac836e97bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpytextrank\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextRank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pytextrank' has no attribute 'TextRank'"
     ]
    }
   ],
   "source": [
    "tr = pytextrank.TextRank(logger=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
